{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "CS 5740 Project 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqij5mWBV3Rv",
        "colab_type": "text"
      },
      "source": [
        "**Team Brooklyn:**\n",
        "\n",
        "*   Jiayi Bao, jb2578\n",
        "*   Siqi Dai, sd854\n",
        "*   Guanyunbo Yang, gy92"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaHrtkqUEKR",
        "colab_type": "text"
      },
      "source": [
        "# Opinion Spam Classification using Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIsEBGb2UKI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAojvcEcVJvm",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Mounting Google Drive and Retrieve Dataset </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As938nutnBDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "path = \"/content/gdrive/My Drive/P1/DATASET/\"  # path that stores the dataset folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6NeT1A-iXuT",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Data Preprocessing </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugiliTFXmEkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing the corpus\n",
        "def preprocess(fn):\n",
        "  with open(fn) as f:\n",
        "    content = f.readlines()\n",
        "  content = [\"<s> \" + x.strip() for x in content]  # remove '\\n' at end and add <s> to indicate the start of a review\n",
        "  content = \"\".join(content)\n",
        "  for char in ['-', '.', ',', ';', '!', '?', ':', '(', ')', '[', ']', '{', '}',]:  # remove punctuations\n",
        "    content = content.replace(char,'')\n",
        "  corpus = content.lower()  # normalization\n",
        "  for char in [' a ', ' an ', ' the ', ' that ', ' this ', ' these ', ' those ', ' and ', ' but ', ' or ', ' at ', ' in ', ' on ', ' be ', ' is ', ' are ', ' am ', ' were ', ' was ', ' to ', ' with ', ' of ', '/']:  # remove stop words\n",
        "    corpus = corpus.replace(char, ' ')\n",
        "  return corpus\n",
        "\n",
        "\n",
        "# get the preprocessed corpus\n",
        "tru_train, decp_train = preprocess(path + \"train/truthful.txt\"), preprocess(path + \"train/deceptive.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLMAbk7Vie3U",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Unsmoothed Unigram and Bigram </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZTfg5lKcdr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a unigram table over the corpus\n",
        "def unigram_table(content):\n",
        "  word_list = Counter(content.split())  # count every sigle word\n",
        "  word_df = pd.DataFrame.from_dict(word_list, orient='index').reset_index()\n",
        "  word_df.columns = [\"word\",\"count\"]\n",
        "  word_df[\"frequency\"] = word_df[\"count\"]/word_df.shape[0]\n",
        "  word_df = word_df.sort_values(by ='count', ascending=False)\n",
        "  return word_df\n",
        "\n",
        "\n",
        "# build a bigram table over the corpus\n",
        "def bigram_table(content):\n",
        "  word_list2 = Counter(zip(content.split(),content.split()[1:]))  # count every two words\n",
        "  keys = list(word_list2.keys())\n",
        "  # <s> can only be start of a review, delete counts for ('xxx', '<s>')\n",
        "  for i in keys:\n",
        "    if i[1] == '<s>':\n",
        "      del word_list2[i]\n",
        "  word_df2 = pd.DataFrame.from_dict(word_list2, orient='index').reset_index()\n",
        "  word_df2.columns = [\"word\",\"count\"]\n",
        "  word_df2[\"frequency\"] = word_df2[\"count\"]/word_df2.shape[0]\n",
        "  word_df2 = word_df2.sort_values(by ='count', ascending=False)\n",
        "  return word_df2\n",
        "\n",
        "\n",
        "# compute P(word) (unsmoothed)\n",
        "def unigram(corpus, table, word):\n",
        "  if word in table.word.values:\n",
        "    return table.loc[table['word'] == word, 'count'].iloc[0] / len(corpus)\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "  \n",
        "# compute P(word1|word2) (unsmoothed)\n",
        "def bigram(uni_table, bi_table, word1, word2):\n",
        "  if (word2, word1) in list(bi_table.word.values):\n",
        "    count_w1w2 = bi_table.loc[bi_table['word'] == (word2, word1), 'count'].iloc[0]\n",
        "    count_w2 = uni_table.loc[uni_table['word'] == word2, 'count'].iloc[0] \n",
        "    return count_w1w2 / count_w2\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSukioDJINX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create unigram and bigram tables for the unsmoothed corpus\n",
        "tru_train_uni, decp_train_uni = unigram_table(tru_train), unigram_table(decp_train)\n",
        "tru_train_bi, decp_train_bi = bigram_table(tru_train), bigram_table(decp_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0hXNAL3KNiy",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Smoothing and Unknown Word Handling </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QISeldFucdsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# method 1 - handle unknown words by replacing the first occurrence of each word type by <unk>\n",
        "def handle_unk1(corpus):\n",
        "  set = []\n",
        "  c = corpus.split()\n",
        "  for i in range(len(c)):\n",
        "    if c[i] == '<s>': continue\n",
        "    if c[i] not in set:\n",
        "        set.append(c[i])\n",
        "        c[i] = \"<unk>\"\n",
        "  corpus = ' '.join(c)\n",
        "  return corpus \n",
        "\n",
        "\n",
        "# method 2 - handle unknown words: decide k most common terms in advance on the vocab and replace others as '<unk>'\n",
        "def handle_unk2(corpus, uni_table, k):\n",
        "  w = list(uni_table.word.values)\n",
        "  kMostFreq = w[:k]\n",
        "  c = corpus.split()\n",
        "  for i in range(len(c)):\n",
        "    if c[i] == '<s>': continue\n",
        "    if c[i] not in kMostFreq:\n",
        "      c[i] = \"<unk>\"\n",
        "  corpus = ' '.join(c)\n",
        "  return corpus\n",
        "\n",
        "\n",
        "# compute P(word) (smoothed)\n",
        "def unigram_smooth(corpus, table, word, addK):\n",
        "  N = len(corpus)\n",
        "  V = len(table)\n",
        "  if word in table.word.values:\n",
        "    return (table.loc[table['word'] == word, 'count'].iloc[0] + addK) / (N + addK*V)\n",
        "  else:\n",
        "    return 0 if addK == 0 else 1 / (N + V)\n",
        "  \n",
        "\n",
        "# compute P(word1|word2) (smoothed)\n",
        "def bigram_smooth(uni_table, bi_table, word1, word2, addK):\n",
        "  V = len(uni_table)\n",
        "  if word2 in uni_table.word.values:\n",
        "    count_w2 = uni_table.loc[uni_table['word'] == word2, 'count'].iloc[0]\n",
        "  else:\n",
        "    count_w2 = 1\n",
        "  if (word2, word1) in list(bi_table.word.values):\n",
        "    count_w1w2 = bi_table.loc[bi_table['word'] == (word2, word1), 'count'].iloc[0]\n",
        "    return (count_w1w2 + addK) / (count_w2 + addK*V)\n",
        "  else:\n",
        "    #return 1 / (count_w2 + V)\n",
        "    return 0 if addK == 0 else addK / (addK * V)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMQg5yKkcUcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model parameters\n",
        "K = 500  # K most common terms\n",
        "addK = 1  # add-k smoothing\n",
        "\n",
        "# update the corpus （handle '<unk>'）\n",
        "# tru_train_smooth = handle_unk1(tru_train)\n",
        "# decp_train_smooth = handle_unk1(decp_train)\n",
        "tru_train_smooth = handle_unk2(tru_train, tru_train_uni, K)\n",
        "decp_train_smooth = handle_unk2(decp_train, decp_train_uni, K)\n",
        "\n",
        "# update unigram and bigram tables for the smoothed corpus\n",
        "tru_train_uni_smooth, decp_train_uni_smooth = unigram_table(tru_train_smooth), unigram_table(decp_train_smooth)\n",
        "tru_train_bi_smooth, decp_train_bi_smooth = bigram_table(tru_train_smooth), bigram_table(decp_train_smooth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcPGg0I4SMIY",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Perplexity </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-05ktD_SN_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plexity_unigram(train_corpus, val_corpus, uni_table, addK):\n",
        "  \"\"\"\n",
        "  train_corpus: train corpus\n",
        "  val_corpus: validation corpus after preprocessing\n",
        "  uni_table: unigram table\n",
        "  \"\"\"\n",
        "  N = len(val_corpus.split())\n",
        "  s = 0\n",
        "  for i in range(N):\n",
        "    P_wi = unigram_smooth(train_corpus, uni_table, val_corpus.split()[i], addK) # compute P(wi|wi-1...w1)\n",
        "    s += 100 if P_wi == 0 else -math.log(P_wi, 10)\n",
        "  ans = math.exp(s / N)\n",
        "  return ans\n",
        "\n",
        "\n",
        "def plexity_bigram(train_corpus, val_corpus, uni_table, bi_table, addK):\n",
        "  \"\"\"\n",
        "  train_corpus: train corpus\n",
        "  val_corpus: validation corpus after preprocessing\n",
        "  bi_model: bigram table\n",
        "  \"\"\"\n",
        "  N = len(val_corpus.split())\n",
        "  s = 0\n",
        "  for i in range(1, N):\n",
        "    if val_corpus[i] == '<s>': continue\n",
        "    P_wi = bigram_smooth(uni_table, bi_table, val_corpus.split()[i], val_corpus.split()[i-1], addK) # compute P(wi|wi-1...w1)\n",
        "    s += 100 if P_wi == 0 else -math.log(P_wi, 10)\n",
        "  ans = math.exp(s / N)\n",
        "  return ans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZplN79Dx9XF",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> LM-based Classification </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG33McFGyF2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standard way: measure the perplexity of the ”truthful” vs. the ”deceptive” language models on a given review: \n",
        "# return the class (truthful, deceptive) associated with the model that produces the lower perplexity score\n",
        "import csv\n",
        "\n",
        "def preprocess_test_corpus(fn):\n",
        "  with open(fn) as f:\n",
        "    content = f.readlines()\n",
        "  content = [\"<s> \" + x.strip() for x in content]  # remove '\\n' at end and add <s> to indicate the start of a review\n",
        "  for i in range(len(content)):\n",
        "    for char in ['-', '.', ',', ';', '!', '?', ':', '(', ')', '[', ']', '{', '}',]:  # remove punctuations\n",
        "      content[i] = content[i].replace(char,'')\n",
        "      content[i] = content[i].lower()  # normalization\n",
        "    for char in [' a ', ' an ', ' the ', ' that ', ' this ', ' these ', ' those ', ' and ', ' but ', ' or ', ' at ', ' in ', ' on ', ' be ', ' is ', ' are ', ' am ', ' were ', ' was ', ' to ', ' with ', ' of ', '/']:  # remove stop words\n",
        "      content[i] = content[i].replace(char, ' ')\n",
        "  return content\n",
        "\n",
        "def perplexity_classify(test_corpus, real_label, file, ngram):\n",
        "  '''\n",
        "  test_corpus: the corpus to classify\n",
        "  real_label: the real label of the corpus\n",
        "  '''\n",
        "  with open(file, 'w', encoding='utf-8-sig') as fileout:\n",
        "    writer = csv.writer(fileout, delimiter=',')\n",
        "    writer.writerow(['Id','Prediction'])\n",
        "    \n",
        "    N = len(test_corpus)\n",
        "    num_wrong_label = 0\n",
        "    for i in range(0, N):\n",
        "      perp_tru = 0\n",
        "      perp_decp = 0\n",
        "      if ngram == 1:\n",
        "        perp_tru = plexity_unigram(tru_train, test_corpus[i], tru_train_uni_smooth, addK)\n",
        "        perp_decp = plexity_unigram(decp_train, test_corpus[i], decp_train_uni_smooth, addK)\n",
        "        \n",
        "      if ngram == 2:\n",
        "        perp_tru = plexity_bigram(tru_train, test_corpus[i], tru_train_uni_smooth, tru_train_bi_smooth, addK)\n",
        "        perp_decp = plexity_bigram(decp_train, test_corpus[i], decp_train_uni_smooth, decp_train_bi_smooth, addK)\n",
        "      \n",
        "      label = 0 if perp_tru < perp_decp else 1\n",
        "      writer.writerow([i, label])\n",
        "      if real_label != -1:\n",
        "        num_wrong_label += abs(label - real_label)\n",
        "    if real_label != -1:\n",
        "      print(\"Accuracy = \", 1 - num_wrong_label / N)\n",
        "    \n",
        "  print(\"Classification Done\")\n",
        "  \n",
        "tru_val, decp_val = preprocess_test_corpus(path+\"validation/truthful.txt\"), preprocess_test_corpus(path + \"validation/deceptive.txt\")\n",
        "test = preprocess_test_corpus(path + \"test/test.txt\")\n",
        "print('Classifying tru_val')\n",
        "perplexity_classify(tru_val, 0, \"truthful_out.csv\", 1)\n",
        "print('Classifying decp_val')\n",
        "perplexity_classify(decp_val, 1, \"deceptive_out.csv\", 1)\n",
        "#print('Classifying test')\n",
        "#perplexity_classify(test, -1, \"test_out.csv\", 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlXKPnKG9hEF",
        "colab_type": "text"
      },
      "source": [
        "# Opinion Spam Classification using Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qzIgV4d-94G",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Read Data </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ky0zDRB9llh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(fn): \n",
        "    with open(fn) as f:\n",
        "        x = f.readlines()\n",
        "    print(fn + \" corpus has\",len(x),\"samples\")\n",
        "    return x\n",
        "  \n",
        "xtrain_true, xtrain_false = read_data(path + \"train/truthful.txt\"), read_data(path + \"train/truthful.txt\")\n",
        "xval_true, xval_false =  read_data(path + \"validation/truthful.txt\"), read_data(path + \"validation/deceptive.txt\")\n",
        "xtrain_raw = xtrain_true + xtrain_false\n",
        "xval_raw = xval_true + xval_false\n",
        "ytrain = [0] * len(xtrain_true) + [1] * len(xtrain_false)  # truthful -> 0, deceptive -> 1\n",
        "yval = [0] * len(xval_true) + [1] * len(xval_false)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpzGarbT976B",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Data Preprocessing </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElgiJCT99q_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# preprocess raw data\n",
        "def preprocess(data_raw):\n",
        "    ps = PorterStemmer()\n",
        "    x = []\n",
        "    for review in data_raw:\n",
        "        \n",
        "        # remove punctuation \n",
        "        review = re.sub('[^A-Za-z]', ' ', review)\n",
        "        tokenized = word_tokenize(review)\n",
        "\n",
        "        for i in range(len(tokenized)):\n",
        "            tokenized[i] = ps.stem(tokenized[i])\n",
        "        \n",
        "        r = \" \".join(tokenized)  # group word back to sentence \n",
        "        x.append(r)\n",
        "        \n",
        "    return x\n",
        "\n",
        "xtrain = preprocess(xtrain_raw)\n",
        "xval = preprocess(xval_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5tWmNzL-UNr",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Feature generation by vectorizing samples with Bag of Word representation  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nld694n-Vhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "def feature_extraction(train, df_min, df_max, ngram_min, ngram_max):\n",
        "    vectorizer = CountVectorizer(min_df = df_min, max_df = df_max,ngram_range = (ngram_min, ngram_max))\n",
        "    xtrain = vectorizer.fit_transform(train).todense()\n",
        "    print(\"#features for ngram (\"+str(ngram_min)+\" , \"+str(ngram_max)+\") = \"+str(len(vectorizer.vocabulary_ )))\n",
        "    return xtrain, vectorizer\n",
        "\n",
        "xtrain1,vectorizer = feature_extraction(xtrain,4,0.75,1,1)\n",
        "xtrain2,bigram_vectorizer = feature_extraction(xtrain,4,0.75,2,2)\n",
        "xtrain3,trigram_vectorizer = feature_extraction(xtrain,4,0.75,3,3)\n",
        "xtrain4,mixgram_vectorizer = feature_extraction(xtrain,4,0.75,1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoR_SSB0-aXh",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Train a Naive Bayes classifier\n",
        "\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccwtkr1X-Zu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train a Naive Bayes classifier\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# train a naive bayes classifier and store acc result in an result array \n",
        "def model_training(alf, xtrain, ytrain, xval, yval, vectorizer):\n",
        "    model = MultinomialNB(alpha=alf, class_prior=None, fit_prior=True)\n",
        "    model.fit(xtrain, ytrain)\n",
        "    \n",
        "    xval = vectorizer.transform(xval).todense()\n",
        "    train_pred = model.predict(xtrain) \n",
        "    val_pred = model.predict(xval) \n",
        "    result = [np.mean(train_pred == ytrain), np.mean(val_pred == yval)]\n",
        "    return model, result, val_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk-mmaC2-kLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unigram\n",
        "uni_model, uni_result, uni_pred= model_training(1, xtrain1, ytrain, xval, yval, vectorizer)\n",
        "print(\"[unigram features] Naive Bayes training acc:\", uni_result[0])   \n",
        "print(\"[unigram features] Naive Bayes validation acc:\", uni_result[1])  \n",
        "\n",
        "# bigram\n",
        "bi_model, bi_result, bi_pred = model_training(1, xtrain2, ytrain, xval, yval, bigram_vectorizer)\n",
        "print(\"\\n[bigram features] Naive Bayes training acc:\", bi_result[0])   \n",
        "print(\"[bigram features] Naive Bayes validation acc:\", bi_result[1])  \n",
        "\n",
        "# trigram\n",
        "tri_model, tri_result, tri_pred = model_training(1, xtrain3, ytrain, xval, yval, trigram_vectorizer)\n",
        "print(\"\\n[trigram features] Naive Bayes training acc:\", tri_result[0])   \n",
        "print(\"[trigram features] Naive Bayes validation acc:\", tri_result[1])   \n",
        "\n",
        "# mixgram (1 and 2 gram)\n",
        "mix_model, mix_result, mix_pred = model_training(1, xtrain4, ytrain, xval, yval, mixgram_vectorizer)\n",
        "print(\"\\n[mixgram features] Naive Bayes training acc:\", mix_result[0])   \n",
        "print(\"[mixgram features] Naive Bayes validation acc:\", mix_result[1])   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyYMs-fl-pF6",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Visualization\n",
        "\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWfKs6oO-tC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "uni_fpr, uni_tpr, uni_thresholds = roc_curve(yval, uni_pred)\n",
        "bi_fpr, bi_tpr, bi_thresholds = roc_curve(yval, bi_pred)\n",
        "tri_fpr, tri_tpr, tri_thresholds = roc_curve(yval, tri_pred)\n",
        "mix_fpr, mix_tpr, mix_thresholds = roc_curve(yval, mix_pred)\n",
        "\n",
        "# create plot\n",
        "plt.plot(uni_fpr, uni_tpr, label='[unigram] ROC curve')\n",
        "plt.plot(bi_fpr, bi_tpr, label='[bigram] ROC curve')\n",
        "plt.plot(tri_fpr, tri_tpr, label='[trigram] ROC curve')\n",
        "plt.plot(mix_fpr, mix_tpr, label='[mixgram] ROC curve')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
        "_ = plt.xlabel('False Positive Rate')\n",
        "_ = plt.ylabel('True Positive Rate')\n",
        "_ = plt.title('ROC Curve For N-gram models')\n",
        "_ = plt.xlim([-0.02, 1])\n",
        "_ = plt.ylim([0, 1.02])\n",
        "_ = plt.legend(loc=\"lower right\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojJiPrYv-5Lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# acc bar chart\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "x = ['unigram', 'bigram', 'trigram', 'mixgram']\n",
        "energy = [uni_acc, bi_acc, tri_acc, mix_acc]\n",
        "x_pos = [i for i, _ in enumerate(x)]\n",
        "plt.ylim([0.7,1])\n",
        "plt.bar(x_pos, energy, color=(0.2, 0.4, 0.6, 0.6))\n",
        "plt.xlabel(\"N-gram models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Naive Bayes Opinion Spam Classification Model\")\n",
        "plt.xticks(x_pos, x)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C92RSil_HFQ",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Most Informative Features¶\n",
        " </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXxB_wfx_F3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=10):\n",
        "    class_labels = classifier.classes_\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
        "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
        "\n",
        "    for coef, feat in topn_class1:\n",
        "        print(class_labels[0], coef, feat)\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    for coef, feat in reversed(topn_class2):\n",
        "        print(class_labels[1], coef, feat)\n",
        "\n",
        "\n",
        "most_informative_feature_for_binary_classification(mixgram_vectorizer, mix_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvQIQL-__QIp",
        "colab_type": "text"
      },
      "source": [
        "### <font color='navy'> Predict on Text Data \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoUMqHuy_Pa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "with open(\"test.txt\") as f:\n",
        "    xtest_raw = f.readlines()\n",
        "print(\"Test set has\",len(xtest_raw),\"samples\")\n",
        "\n",
        "x = preprocess(xtest_raw)\n",
        "xtest = mixgram_vectorizer.transform(x).todense()  \n",
        "print(xtest.shape)\n",
        "test_pred = mix_model.predict(xtest)\n",
        "a = np.array(test_pred)\n",
        "\n",
        "with open('output.csv', 'w', encoding='utf-8-sig') as fh:\n",
        "    writer = csv.writer(fh, delimiter=',')\n",
        "    writer.writerow(['Id','Prediction'])\n",
        "    writer.writerows(enumerate(a))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}